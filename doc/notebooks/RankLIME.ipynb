{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sentence_transformers import CrossEncoder"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#Distilled LLMs the decisions of which we try to explain\n",
    "model1 = CrossEncoder('cross-encoder/ms-marco-TinyBERT-L-2', max_length=512)\n",
    "model2 = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2', max_length=512)\n",
    "model3 = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2', max_length=512)\n",
    "model4 = CrossEncoder('cross-encoder/ms-marco-electra-base', max_length=512)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#A Query and a set of 8 relevant passages from the MS MARCO passage reranking dataset\n",
    "query = \"definition of gross salary verus basic salary\"\n",
    "\n",
    "par1 = \"Basic Definition. Gross salary is the term used to describe all of the money youâve made while working at your job, figured before any deductions are taken for state and federal taxes, Social Security and health insurance.\"\n",
    "par2 = \"Gross pay is the total amount you earn. For example, if you earn $15 per hour and work eight hours a day, your gross pay for that day is 8 x $15, or $120. Net pay is the amount you actually receive after any preliminary taxes are removed, such as Social Security, federal taxes and money toward workers' compensation.\"\n",
    "par3 = \"Gross salary is the term used to describe all of the money youâve made while working at your job, figured before any deductions are taken for state and federal taxes, Social Security and health insurance.\"\n",
    "par4 = \"You may receive a monthly or daily salary. Daily wages are calculated using either the gross rate (for paid public holidays, paid leave, salary in lieu and salary deductions) or the basic rate (for work on rest days or public holidays).\"\n",
    "par5 = \"Gross vs. Net. Gross pay is the total amount you earn. For example, if you earn $15 per hour and work eight hours a day, your gross pay for that day is 8 x $15, or $120.\"\n",
    "par6 = \"Basic salary is the fixed salary, invariable, minimum wages, mandatory pay, fixed by the company to pay the employees. As per the legislative fixation, 30% to 60% of your salary shall be your basic pay, i.e., not less than 30% of your gross pay or take home salary ans not more than 60%, shall be basic pay.\"\n",
    "par7 = \"The company salary policy is basic 40% of gross, hra 24% of gross, ca 18% of gross & ma 18% of gross. company calculating pf deduction on basic (40% of gross), but for bonus calculation compny consider basic wages is (basic+ca+ma).\"\n",
    "par8 = \"Gross pay is the total amount you earn. For example, if you earn $15 per hour and work eight hours a day, your gross pay for that day is 8 x $15, or $120.\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#Predicting each passage's relevance to the query based on different LLMs \n",
    "scores1 = model1.predict([(query, par1), (query, par2) , (query, par3), (query,par4),(query, par5), (query, par6) , (query, par7), (query,par8)])\n",
    "scores2 = model2.predict([(query, par1), (query, par2) , (query, par3), (query,par4),(query, par5), (query, par6) , (query, par7), (query,par8)])\n",
    "scores3 = model3.predict([(query, par1), (query, par2) , (query, par3), (query,par4),(query, par5), (query, par6) , (query, par7), (query,par8)])\n",
    "scores4 = model4.predict([(query, par1), (query, par2) , (query, par3), (query,par4),(query, par5), (query, par6) , (query, par7), (query,par8)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#Function to generate the document order from the output of various ranking models \n",
    "def order_func(s):\n",
    "    return sorted(range(len(s)), key=lambda k: -s[k])\n",
    "\n",
    "ord1,ord2,ord3,ord4 = order_func(scores1),order_func(scores2),order_func(scores3),order_func(scores4)\n",
    "print(ord1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 2, 6, 5, 1, 7, 4, 3]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n",
    "\n",
    "\n",
    "class_names = ['irrelevant','relevant']\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "import numpy as np\n",
    "\n",
    "pars = [par1.lower(),par2.lower(),par3.lower(),par4.lower(),par5.lower(),par6.lower(),par7.lower(),par8.lower()]\n",
    "\n",
    "e = explainer.explain_instance(pars, model1, query, num_features=8 )\n",
    "print(e)\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      8\u001b[0m pars \u001b[38;5;241m=\u001b[39m [par1\u001b[38;5;241m.\u001b[39mlower(),par2\u001b[38;5;241m.\u001b[39mlower(),par3\u001b[38;5;241m.\u001b[39mlower(),par4\u001b[38;5;241m.\u001b[39mlower(),par5\u001b[38;5;241m.\u001b[39mlower(),par6\u001b[38;5;241m.\u001b[39mlower(),par7\u001b[38;5;241m.\u001b[39mlower(),par8\u001b[38;5;241m.\u001b[39mlower()]\n\u001b[0;32m---> 10\u001b[0m e \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(e)\n",
      "File \u001b[0;32m~/marco_rerank/lime/lime/lime_text.py:325\u001b[0m, in \u001b[0;36mLimeTextExplainer.explain_instance\u001b[0;34m(self, text_instance, classifier_fn, query, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generates explanations for a prediction.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \n\u001b[1;32m    297\u001b[0m \u001b[38;5;124;03mFirst, we generate neighborhood data by randomly hiding features from\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;124;03m    explanations.\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m#No change above this\u001b[39;00m\n\u001b[0;32m--> 325\u001b[0m indexed_string \u001b[38;5;241m=\u001b[39m \u001b[43mIndexedString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m                                \u001b[49m\u001b[43msplit_expression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_expression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mmask_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask_string\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#class object\u001b[39;00m\n\u001b[1;32m    329\u001b[0m domain_mapper \u001b[38;5;241m=\u001b[39m TextDomainMapper(indexed_string)\n\u001b[1;32m    332\u001b[0m data, _yss, distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__data_labels_distances(\n\u001b[1;32m    333\u001b[0m     indexed_string, classifier_fn, query, num_samples,\n\u001b[1;32m    334\u001b[0m     distance_metric\u001b[38;5;241m=\u001b[39mdistance_metric)\n",
      "File \u001b[0;32m~/marco_rerank/lime/lime/lime_text.py:133\u001b[0m, in \u001b[0;36mIndexedString.__init__\u001b[0;34m(self, raw_string, split_expression, bow, mask_string)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    132\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(word)\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnon_word\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    134\u001b[0m     non_vocab\u001b[38;5;241m.\u001b[39madd(word)\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.10.12 64-bit ('marcoenv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "interpreter": {
   "hash": "da0f0455b1961673cf484d15ab957023a47b109ee2cbf4fbd39031207ed831c8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}